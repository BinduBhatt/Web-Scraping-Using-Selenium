{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70cf22d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success\n",
      "Scraping page 1\n",
      "Page 1 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 2\n",
      "Page 2 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 3\n",
      "Page 3 saved successfully\n",
      "Number of products: 6\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 4\n",
      "Page 4 saved successfully\n",
      "Number of products: 1\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 5\n",
      "Page 5 saved successfully\n",
      "Number of products: 10\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 6\n",
      "Page 6 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 7\n",
      "Page 7 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 8\n",
      "Page 8 saved successfully\n",
      "Number of products: 6\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 9\n",
      "Page 9 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 10\n",
      "Page 10 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 11\n",
      "Page 11 saved successfully\n",
      "Number of products: 5\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 12\n",
      "Page 12 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 13\n",
      "Page 13 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 14\n",
      "Page 14 saved successfully\n",
      "Number of products: 14\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 15\n",
      "Page 15 saved successfully\n",
      "Number of products: 5\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 16\n",
      "Page 16 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 17\n",
      "Page 17 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 18\n",
      "Page 18 saved successfully\n",
      "Number of products: 5\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 19\n",
      "Page 19 saved successfully\n",
      "Number of products: 22\n",
      "Next button found\n",
      "*******************************\n",
      "Scraping page 20\n",
      "Page 20 saved successfully\n",
      "Number of products: 8\n",
      "No more pages found\n",
      "1\n",
      "Data successfully saved to Laptop_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries, module & class\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from amazoncaptcha import AmazonCaptcha\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "username = os.getenv('SCRAPER_USERNAME')\n",
    "password = os.getenv('SCRAPER_PASSWORD')\n",
    "\n",
    "\n",
    "# Path to the chromedriver. Creating the object\n",
    "s= Service(\"C:/Users/Admin/Desktop/chromedriver-win64/chromedriver\")\n",
    "\n",
    "# Initializing the webdriver with service object\n",
    "driver = webdriver.Chrome(service= s)\n",
    "driver.get('https://www.amazon.com/')\n",
    "\n",
    "# Captcha Handling\n",
    "try:\n",
    "    # providing the 10 sec time to webdriver to wait till the page loads and get attribute of the captcha source\n",
    "    image_src = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"\"\"/html/body/div/div[1]/div[3]/div/div/form/div[1]/div/div/div[1]/img\"\"\"))).get_attribute('src')         \n",
    "\n",
    "    # Using AmazonCaptcha Module to retrieve captcha value\n",
    "    captcha = AmazonCaptcha.fromlink(image_src) \n",
    "    captcha_value = AmazonCaptcha.solve(captcha)\n",
    "\n",
    "    # Finding the input field for captcha value and inserting the solved captcha value and continuing \n",
    "    input_field = driver.find_element(By.XPATH, \"\"\"/html/body/div/div[1]/div[3]/div/div/form/div[1]/div/div/div[2]/input\"\"\")\n",
    "    captcha_inp = input_field.send_keys(captcha_value)\n",
    "    condinue_shopping = driver.find_element(By.XPATH, \"\"\"/html/body/div/div[1]/div[3]/div/div/form/div[2]/div/span/span/button\"\"\").click()\n",
    "except Exception as e:\n",
    "    print(f\"Captcha handling failed: {e}\")\n",
    "\n",
    "\n",
    "try: \n",
    "    # locating the accounts field and signing in\n",
    "    driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[3]/div/a[2]/div/span\").click()\n",
    "\n",
    "    # Locating username field and inserting username retrieved above from env file.\n",
    "    user = driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div/div[2]/div[2]/div[1]/form/div/div/div/div[1]/input[1]\"\"\")\n",
    "    user.send_keys(username)    \n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div/div[2]/div[2]/div[1]/form/div/div/div/div[2]/span/span/input').click()\n",
    "\n",
    "    # Locating password field and inserting password retrieved above from env file.\n",
    "    pwd = driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div/div[2]/div/div[2]/div/form/div/div[1]/input\"\"\")\n",
    "    pwd.send_keys(password)\n",
    "    driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div/div[2]/div/div[2]/div/form/div/div[2]/span/span/input\"\"\").click()\n",
    "    print('login success')\n",
    "    \n",
    "    # Data Scraping\n",
    "    search_bar = driver.find_element(By.XPATH, \"\"\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\"\"\")\n",
    "    search_bar.send_keys(\"laptops\")\n",
    "    search_bar.send_keys(Keys.ENTER)\n",
    "    \n",
    "    \n",
    "    # wait for the page to load\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"\"\"/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]\"\"\")))\n",
    "    \n",
    "    # open excel file and create new sheet\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    \n",
    "    # column headers\n",
    "    ws['A1'] = 'Name'\n",
    "    ws['B1'] = 'Price'\n",
    "    ws['C1'] = 'Review'\n",
    "    \n",
    "    page = 0\n",
    "    while page <= 20:\n",
    "        print(f\"Scraping page {page + 1}\")\n",
    "        # saving the page as html as Amazon doesn't let scraping the data\n",
    "        with open('Amazon.html','w', encoding = 'utf-8') as file:\n",
    "            file.write(driver.page_source)\n",
    "            print(f\"Page {page + 1} saved successfully\")\n",
    "\n",
    "        with open('Amazon.html', 'r', encoding = 'utf-8') as f:\n",
    "            html_page = f.read()\n",
    "\n",
    "        # get page source and parse it with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "  \n",
    "        products = soup.find_all('div', class_=\"puis-card-container s-card-container s-overflow-hidden aok-relative puis-include-content-margin puis puis-v1ptg7iq6f5f4u2smovb1ai55ug s-latency-cf-section puis-card-border\")\n",
    "        print(f'Number of products: {len(products)}')\n",
    "        row = ws.max_row +1\n",
    "        \n",
    "        for product in products:\n",
    "            try:\n",
    "                product_name = product.find(\"span\" , class_= \"a-size-medium a-color-base a-text-normal\").text.strip()\n",
    "                price = product.find(\"span\", class_ = 'a-price-whole').text.strip()\n",
    "                price_val_dollars = ''.join(filter(str.isdigit, price))\n",
    "                rating = product.find(\"span\",class_= \"a-icon-alt\").text.strip()\n",
    "                rating_val = rating.split()[0]\n",
    " \n",
    "\n",
    "                # write data to excel sheet\n",
    "                ws.cell(row = row, column = 1, value = product_name)\n",
    "                ws.cell(row = row, column = 2, value = price_val_dollars)\n",
    "                ws.cell(row = row, column = 3, value = rating_val)\n",
    "\n",
    "                 # move to next row\n",
    "                row +=1\n",
    "\n",
    "\n",
    "            except AttributeError:\n",
    "                continue\n",
    "            \n",
    "        # Page increment       \n",
    "        page +=1  \n",
    "        \n",
    "        # Check for next button to move to the next page\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, \"//a[contains(@class, 's-pagination-next')]\")\n",
    "            if next_button and next_button.is_enabled():\n",
    "                print(\"Next button found\")\n",
    "                print(\"*******************************\")\n",
    "                next_button.click()\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@data-component-type='s-search-result']\")))\n",
    "            else:\n",
    "                print('No more pages available or next button not enabled')\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(\"No more pages found\")\n",
    "            break\n",
    "        \n",
    "    wb.save('Laptop_prices.xlsx')\n",
    "    print(\"Data successfully saved to Laptop_prices.xlsx\") \n",
    "\n",
    "    # Exception Handling\n",
    "except NoSuchElementException as e:\n",
    "    print(f\"No Such element found: {e}\")\n",
    "except TimeoutException as e:\n",
    "    print(f\"Time out. Waiting to load: {e}\")\n",
    "except WebDriverException as e:\n",
    "    print(f\"Web driver function error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occured: {e}\")\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa209ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842898b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98ef24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
